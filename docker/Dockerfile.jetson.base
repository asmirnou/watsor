FROM nvcr.io/nvidia/l4t-tensorrt:r8.5.2-runtime AS base

# Install basic packages
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    wget \
    unzip \
    gnupg2 \
    python3-pip \
    && python3 -m pip install --upgrade \
        pip \
        setuptools \
        wheel \
    && rm -rf /var/lib/apt/lists/*

#
# Use another image with CUDA headers as a new temporary stage for building libraries
#
FROM nvcr.io/nvidia/l4t-tensorrt:r8.5.2.2-devel AS builder

LABEL watsor.builder="watsor.jetson.base.builder"

# Install Python modules
ENV CPATH=$CPATH:/usr/local/cuda/targets/aarch64-linux/include
ENV LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda/targets/aarch64-linux/lib

# Build Wheel archives for the requirements and dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    build-essential \
    python3-pip \
    python3-dev \
    && python3 -m pip install --upgrade \
        pip \
        setuptools \
        wheel \
    && rm -rf /var/lib/apt/lists/* \
    && python3 -m pip wheel --wheel-dir=/tmp/install \
        numpy \
        scipy \
        opencv-python-headless \
        PyYaml \
        cerberus \
        shapely \
        werkzeug \
        paho-mqtt \
        pycuda \
        six \
        https://github.com/google-coral/pycoral/releases/download/v2.0.0/tflite_runtime-2.5.0.post1-cp38-cp38-linux_aarch64.whl

#
# Copy libraries to the final image
#
FROM base AS result

COPY --from=builder /tmp/install /tmp/install

# Install Wheel archives built at previous stage
RUN python3 -m pip install --upgrade /tmp/install/* \
    && rm -r /tmp/install

# Install FFmpeg with hardware accelerated decoder
RUN echo "deb https://repo.download.nvidia.com/jetson/ffmpeg main main" | tee -a /etc/apt/sources.list \
    && wget -q -O - https://repo.download.nvidia.com/jetson/jetson-ota-public.asc | apt-key add - \
    && apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Install the Edge TPU runtime
RUN echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | tee /etc/apt/sources.list.d/coral-edgetpu.list \
    && wget -q -O - https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \
    && apt-get update && apt-get install -y --no-install-recommends \
        libedgetpu1-std \
        python3-pycoral \
    && rm -rf /var/lib/apt/lists/*

# Dedicated user
RUN mkdir /etc/watsor /usr/share/watsor /var/log/watsor && \
    addgroup -gid 1001 watsor && \
    adduser -uid 1001 -gid 1001 -gecos watsor -home /usr/share/watsor --no-create-home --disabled-password watsor && \
    usermod -a --groups video,plugdev watsor && \
    chown -R watsor /etc/watsor /usr/share/watsor /var/log/watsor

# Download object detection models
RUN mkdir model \
    && wget -q https://github.com/google-coral/test_data/raw/master/ssdlite_mobiledet_coco_qat_postprocess_edgetpu.tflite -O model/edgetpu.tflite \
    && wget -q https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -O model/cpu.zip \
    && wget -q https://github.com/asmirnou/todus/raw/models/ssd_mobilenet_v2_coco_2018_03_29.uff -O model/gpu.uff \
    && unzip model/cpu.zip detect.tflite -d model \
    && rm model/cpu.zip \
    && mv model/detect.tflite model/cpu.tflite \
    && mv model /usr/share/watsor/model \
    && chown -R watsor:watsor /usr/share/watsor/model

EXPOSE 8080

ENV TRT_FLOAT_PRECISION=16
ENV CUDA_MODULE_LOADING=LAZY